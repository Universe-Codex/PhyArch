<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>PhyArch NEXUS v13 â€” Sensory Singularity</title>

  <script src="https://cdn.jsdelivr.net/npm/three@0.168.0/build/three.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/three@0.168.0/examples/js/controls/OrbitControls.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/cannon-es@0.20.0/dist/cannon-es.min.js"></script>

  <style>
    :root { --accent: #00ffb2; --bg: #010105; --ui-glass: rgba(5, 5, 12, 0.9); }
    * { margin:0; padding:0; box-sizing:border-box; cursor: none !important; }
    body { background:var(--bg); color:#fff; font-family: 'JetBrains Mono', monospace; overflow:hidden; }

    /* --- PERMISSION OVERLAY --- */
    #neural-link {
      position: fixed; inset: 0; background: #000; z-index: 20000;
      display: flex; flex-direction: column; align-items: center; justify-content: center;
      transition: opacity 1s;
    }

    #cursor { position: fixed; width: 20px; height: 20px; border: 1px solid var(--accent); border-radius: 50%; pointer-events: none; z-index: 10000; }

    .widget { position: fixed; background: var(--ui-glass); backdrop-filter: blur(20px); border: 1px solid rgba(255,255,255,0.1); border-radius: 12px; padding: 20px; z-index: 1000; }
    #sensor-widget { top: 20px; left: 20px; width: 300px; }
    
    .btn { background: var(--accent); color: #000; border: none; padding: 12px; width: 100%; border-radius: 6px; font-weight: 800; cursor: pointer; margin-top: 10px; }
    .sensor-led { width: 8px; height: 8px; border-radius: 50%; display: inline-block; margin-right: 8px; background: #333; }
    .led-active { background: var(--accent); box-shadow: 0 0 10px var(--accent); }

    .scanline { position:fixed; inset:0; background: repeating-linear-gradient(0deg, transparent 0, transparent 2px, rgba(0,255,178,0.03) 2px, rgba(0,255,178,0.03) 4px); pointer-events:none; }
  </style>
</head>
<body>

<div id="neural-link">
  <div style="text-align:center; max-width: 400px;">
    <h1 style="letter-spacing: 15px; color: var(--accent); margin-bottom: 20px;">NEXUS_v13</h1>
    <p style="font-size: 10px; opacity: 0.6; line-height: 2;">AUTHORIZE SENSORY INPUTS FOR NEURAL SOUNDSCAPE AND SPATIAL ACCELEROMETER MAPPING</p>
    <button class="btn" onclick="initSensors()">INITIALIZE NEURAL LINK</button>
  </div>
</div>

<div id="cursor"></div>

<div id="sensor-widget" class="widget">
  <span style="font-size: 10px; letter-spacing: 2px; opacity: 0.7;">SENSORY TELEMETRY</span>
  <div style="margin-top:15px; font-size: 11px;">
    <div><span id="led-audio" class="sensor-led"></span> AUDIO_ENGINE</div>
    <div><span id="led-gyro" class="sensor-led"></span> MOTION_SENSING</div>
    <div style="margin-top:10px; opacity: 0.5;">Tilt device to warp gravity</div>
  </div>
  <button class="btn" style="background:#fff;" onclick="spawn(20)">SPAWN RESONANT MATTER</button>
</div>

<div id="viewport"></div>
<div class="scanline"></div>

<script>
let scene, camera, renderer, world, entities = [];
let audioCtx, osc, mainGain;
let gyroActive = false;

// --- INITIALIZE SENSORS & AUDIO ---
async function initSensors() {
  // 1. Audio Context Initialization
  audioCtx = new (window.AudioContext || window.webkitAudioContext)();
  mainGain = audioCtx.createGain();
  mainGain.gain.setValueAtTime(0.1, audioCtx.currentTime);
  mainGain.connect(audioCtx.destination);
  document.getElementById('led-audio').classList.add('led-active');

  // 2. Motion/Gyroscope Permissions (iOS 13+ specific)
  if (typeof DeviceOrientationEvent.requestPermission === 'function') {
    try {
      const response = await DeviceOrientationEvent.requestPermission();
      if (response === 'granted') {
        window.addEventListener('deviceorientation', handleMotion);
        gyroActive = true;
      }
    } catch (e) { console.error("Motion rejected"); }
  } else {
    window.addEventListener('deviceorientation', handleMotion);
    gyroActive = true;
  }
  
  if(gyroActive) document.getElementById('led-gyro').classList.add('led-active');

  // 3. Clear Overlay
  document.getElementById('neural-link').style.opacity = '0';
  setTimeout(() => document.getElementById('neural-link').style.display = 'none', 1000);
  
  bootEngine();
}

function handleMotion(e) {
  // Map phone tilt to world gravity
  const gx = e.gamma / 5; // Tilt left/right
  const gy = e.beta / 5;  // Tilt forward/back
  world.gravity.set(gx, -9.81, gy);
}

function bootEngine() {
  scene = new THREE.Scene();
  camera = new THREE.PerspectiveCamera(60, window.innerWidth/window.innerHeight, 0.1, 5000);
  camera.position.set(100, 100, 100);

  renderer = new THREE.WebGLRenderer({ antialias: true });
  renderer.setSize(window.innerWidth, window.innerHeight);
  document.getElementById('viewport').appendChild(renderer.domElement);

  new THREE.OrbitControls(camera, renderer.domElement);
  world = new CANNON.World({ gravity: new CANNON.Vec3(0, -9.81, 0) });

  scene.add(new THREE.GridHelper(500, 50, 0x00ffb2, 0x050515));

  window.onmousemove = (e) => {
    document.getElementById('cursor').style.left = e.clientX + 'px';
    document.getElementById('cursor').style.top = e.clientY + 'px';
  };

  animate();
}

function spawn(count) {
  for(let i=0; i<count; i++) {
    const mesh = new THREE.Mesh(new THREE.IcosahedronGeometry(2, 1), new THREE.MeshPhongMaterial({ wireframe: true, color: 0x00ffb2 }));
    const body = new CANNON.Body({ mass: 1, shape: new CANNON.Sphere(2) });
    body.position.set((Math.random()-0.5)*80, 50, (Math.random()-0.5)*80);
    
    // Assign a unique oscillator for soundscape
    const g = audioCtx.createGain();
    const o = audioCtx.createOscillator();
    o.type = 'sine';
    o.connect(g).connect(mainGain);
    o.start();
    g.gain.setValueAtTime(0, audioCtx.currentTime);

    scene.add(mesh);
    world.addBody(body);
    entities.push({ mesh, body, osc: o, gain: g });
  }
}

function animate() {
  requestAnimationFrame(animate);
  world.step(1/60);
  
  entities.forEach(e => {
    e.mesh.position.copy(e.body.position);
    e.mesh.quaternion.copy(e.body.quaternion);

    // NEURAL SOUNDSCAPE MAPPING
    // Map velocity to pitch and volume
    const speed = e.body.velocity.length();
    if(speed > 0.5) {
      const pitch = 100 + (speed * 20);
      e.osc.frequency.setTargetAtTime(pitch, audioCtx.currentTime, 0.1);
      e.gain.gain.setTargetAtTime(Math.min(speed / 100, 0.05), audioCtx.currentTime, 0.1);
    } else {
      e.gain.gain.setTargetAtTime(0, audioCtx.currentTime, 0.1);
    }
    
    // Visual Pulse based on pitch
    e.mesh.scale.setScalar(1 + (speed * 0.05));
  });
  
  renderer.render(scene, camera);
}
</script>
</body>
</html>
